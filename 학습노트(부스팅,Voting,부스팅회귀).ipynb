{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "학습노트(부스팅,Voting,부스팅회귀).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLwmrv4pEmzk"
      },
      "source": [
        "# 부스팅(Boosting)\n",
        "- 기본적으로는 랜덤 포레스트와 유사하다.\n",
        "- 다른 점은 각 트리플들이 던지는 답의 오차들을 보정하여 성능을 끌어올린다.\n",
        "- 너어어어어어어어어무 느리다.\n",
        "\n",
        "- xgboost 설치\n",
        "- pip install xgboost\n",
        "\n",
        "- LightGBM설치\n",
        "- pip install lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmqoqY3RTpVW"
      },
      "source": [
        "## 부스팅 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvsvskB1TpVY"
      },
      "source": [
        "#### 데이터 준비>데이터 전처리(X,y-인코딩( LabelEncoder())-표준화(StandardScaler()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro445kD_Em0I"
      },
      "source": [
        "### 기본 모델 사용 AdaBoostClassifier() ,GradientBoostingClassifier(), LGBMClassifier(), XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J82FVukEphv"
      },
      "source": [
        "model1 = AdaBoostClassifier()\n",
        "\n",
        "# 교차 검증\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "r1 = cross_val_score(model1, X, y, scoring='f1', cv=kfold)\n",
        "print(f'평균 정확도 : {r1.mean()}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_PN-saUEplN"
      },
      "source": [
        "model2 = GradientBoostingClassifier()\n",
        "\n",
        "# 교차 검증\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "r1 = cross_val_score(model1, X, y, scoring='f1', cv=kfold)\n",
        "print(f'평균 정확도 : {r1.mean()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEfWQqGiEpof"
      },
      "source": [
        "model3 = LGBMClassifier()\n",
        "\n",
        "# 교차 검증\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "r1 = cross_val_score(model1, X, y, scoring='f1', cv=kfold)\n",
        "print(f'평균 정확도 : {r1.mean()}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_doNxveFnn4"
      },
      "source": [
        "- silent=True,verbosity=0 ->메시지 출력안하게함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHERgR-xEpuA"
      },
      "source": [
        "# silent=True,verbosity=0 ->메시지 출력안하게함.\n",
        "model4 = XGBClassifier(silent=True,verbosity=0)\n",
        "\n",
        "# 교차 검증\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "r1 = cross_val_score(model1, X, y, scoring='f1', cv=kfold)\n",
        "print(f'평균 정확도 : {r1.mean()}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmAzEVHFEpxY"
      },
      "source": [
        "### 모델 하이퍼 파라미터 튜닝\n",
        "- learning rate : 학습률. 보정 할 때 어느정도로 보정을 할 것인지를 설정한다. \n",
        "- 값이 너무 크면 보정 정도가 크므로 세밀하지 못하지만 속도가 빠르고 값이 작으면 세밀하게 보정을 하지만 속도가 느리다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R963dZQgGAMi"
      },
      "source": [
        "#### AdaBoost\n",
        "- n_estimators : 사용할 트리의 개수\n",
        "- max_depth : 생성될 최대 질문 깊이, None은 무한대."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lo2aLUYEp0w"
      },
      "source": [
        "#AdaBoost\n",
        "\n",
        "params = {\n",
        "    'learning_rate' : [0.0001,0.001,0.01,0.1,1,10,100,1000,10000],\n",
        "    'n_estimators' : [50, 100, 150, 200, 250, 300],\n",
        "#     'max_depth' : [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "}\n",
        "\n",
        "model1 = AdaBoostClassifier(random_state=1)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "grid_clf1 = GridSearchCV(model1, param_grid=params, scoring='f1', cv=kfold)\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "grid_clf1.fit(X, y)\n",
        "\n",
        "end = datetime.datetime.now()\n",
        "\n",
        "print(f'최적의 하이퍼 파라미터 : {grid_clf1.best_params_}')\n",
        "print(f'최적의 모델 평균 성능 : {grid_clf1.best_score_}')\n",
        "print(f'총 튜닝 시간 : {end - start}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPszgqSVEp4n"
      },
      "source": [
        "#### GradianBoosting\n",
        "- learning_rate : 학습률\n",
        "- n_estimators : 사용할 트리의 개수\n",
        "- max_depth : 생성될 최대 질문 깊이, None은 무한대."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0zYT-3gGMFN"
      },
      "source": [
        "params = {\n",
        "    'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
        "    'n_estimators' : [50, 100, 150, 200, 250, 300],\n",
        "    # 'max_depth' : [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "}\n",
        "\n",
        "model2 = GradientBoostingClassifier()\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "grid_clf2 = GridSearchCV(model2, param_grid=params, scoring='f1', cv=kfold)\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "grid_clf2.fit(X, y)\n",
        "\n",
        "end = datetime.datetime.now()\n",
        "\n",
        "print(f'최적의 하이퍼 파라미터 : {grid_clf2.best_params_}')\n",
        "print(f'최적의 모델 평균 성능 : {grid_clf2.best_score_}')\n",
        "print(f'총 튜닝 시간 : {end - start}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJNZkLFfGMIB"
      },
      "source": [
        "#### Light Gradian Boosting Machine\n",
        "- learning_rate : 학습률\n",
        "- n_estimators : 사용할 트리의 개수\n",
        "- max_depth : 생성될 최대 질문 깊이, None은 무한대."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pveQFrsYGMNJ"
      },
      "source": [
        "params = {\n",
        "    'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
        "    'n_estimators' : [50, 100, 150, 200, 250, 300],\n",
        "    # 'max_depth' : [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "}\n",
        "\n",
        "model3 =LGBMClassifier()\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "grid_clf3 = GridSearchCV(model3, param_grid=params, scoring='f1', cv=kfold)\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "grid_clf3.fit(X, y)\n",
        "\n",
        "end = datetime.datetime.now()\n",
        "\n",
        "print(f'최적의 하이퍼 파라미터 : {grid_clf3.best_params_}')\n",
        "print(f'최적의 모델 평균 성능 : {grid_clf3.best_score_}')\n",
        "print(f'총 튜닝 시간 : {end - start}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AacjHb9YGMP6"
      },
      "source": [
        "#### XGBoost\n",
        "- booster : 내부에 사용할 알고리즘\n",
        "- learning_rate : 학습률\n",
        "- n_estimators : 사용할 트리의 개수\n",
        "- max_depth : 생성될 최대 질문 깊이, None은 무한대"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHi8fXq1GMSc"
      },
      "source": [
        "params = {\n",
        "    'booster' : ['gbtree', 'gblinear'],\n",
        "    'learning_rate' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
        "    'n_estimators' : [50, 100, 150, 200, 250, 300],\n",
        "    # 'max_depth' : [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "}\n",
        "\n",
        "model4 = XGBClassifier(silent=True, verbosity=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "grid_clf4 = GridSearchCV(model4, param_grid=params, scoring='f1', cv=kfold)\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "grid_clf4.fit(X, y)\n",
        "\n",
        "end = datetime.datetime.now()\n",
        "\n",
        "print(f'최적의 하이퍼 파라미터 : {grid_clf4.best_params_}')\n",
        "print(f'최적의 모델 평균 성능 : {grid_clf4.best_score_}')\n",
        "print(f'총 튜닝 시간 : {end - start}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M7637mhEm0b"
      },
      "source": [
        "### 최적의 파라미터의 학습 데이터를 넣어 시각화 해본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYHRhJhpGqp2"
      },
      "source": [
        "# 최적의 하이퍼파라미터가 셋팅된 모델을 받아온다.\n",
        "best_model1 = grid_clf1.best_estimator_ #AdaBoost\n",
        "best_model2 = grid_clf2.best_estimator_ # GradianBoosting\n",
        "best_model3 = grid_clf3.best_estimator_ # Light Gradian Boosting Machine\n",
        "best_model4 = grid_clf4.best_estimator_ # XGBoost\n",
        "\n",
        "# 학습\n",
        "best_model1.fit(X, y)\n",
        "best_model2.fit(X, y)\n",
        "best_model3.fit(X, y)\n",
        "best_model4.fit(X, y)\n",
        "\n",
        "\n",
        "# 예측결과를 시각화 해본다.\n",
        "y_pred1 = best_model1.predict(X)\n",
        "plt.scatter(list(range(len(y))), y, label='original')\n",
        "plt.scatter(list(range(len(y_pred1))), y_pred1, label='prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "y_pred2 = best_model2.predict(X)\n",
        "plt.scatter(list(range(len(y))), y, label='original')\n",
        "plt.scatter(list(range(len(y_pred2))), y_pred2, label='prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "y_pred3 = best_model3.predict(X)\n",
        "plt.scatter(list(range(len(y))), y, label='original')\n",
        "plt.scatter(list(range(len(y_pred3))), y_pred3, label='prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "y_pred4 = best_model4.predict(X)\n",
        "plt.scatter(list(range(len(y))), y, label='original')\n",
        "plt.scatter(list(range(len(y_pred4))), y_pred4, label='prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 결과 확률\n",
        "proba_a1 = best_model1.predict_proba(X)\n",
        "\n",
        "# 0일 확률들\n",
        "a10 = proba_a1[:, 0]\n",
        "# 1일 확률들\n",
        "a11 = proba_a1[:, 1]\n",
        "\n",
        "plt.scatter(list(range(len(a10))), a10, label='0일 확률')\n",
        "plt.scatter(list(range(len(a11))), a11, label='1일 확률')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 결과 확률\n",
        "proba_a1 = best_model2.predict_proba(X)\n",
        "\n",
        "# 0일 확률들\n",
        "a10 = proba_a1[:, 0]\n",
        "# 1일 확률들\n",
        "a11 = proba_a1[:, 1]\n",
        "\n",
        "plt.scatter(list(range(len(a10))), a10, label='0일 확률')\n",
        "plt.scatter(list(range(len(a11))), a11, label='1일 확률')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 결과 확률\n",
        "proba_a1 = best_model3.predict_proba(X)\n",
        "\n",
        "# 0일 확률들\n",
        "a10 = proba_a1[:, 0]\n",
        "# 1일 확률들\n",
        "a11 = proba_a1[:, 1]\n",
        "\n",
        "plt.scatter(list(range(len(a10))), a10, label='0일 확률')\n",
        "plt.scatter(list(range(len(a11))), a11, label='1일 확률')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 결과 확률\n",
        "proba_a1 = best_model4.predict_proba(X)\n",
        "\n",
        "# 0일 확률들\n",
        "a10 = proba_a1[:, 0]\n",
        "# 1일 확률들\n",
        "a11 = proba_a1[:, 1]\n",
        "\n",
        "plt.scatter(list(range(len(a10))), a10, label='0일 확률')\n",
        "plt.scatter(list(range(len(a11))), a11, label='1일 확률')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtdt51aQEm0f"
      },
      "source": [
        "### 새로운 데이터 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkgEIWZ3TpVq"
      },
      "source": [
        "#### 데이터 준비>데이터 전처리(표준화(StandardScaler())>결과 예측>시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFTQYSvVGq1U"
      },
      "source": [
        "df2 = pd.read_csv('data/breast_cancer_new.csv')\n",
        "\n",
        "# 데이터 표준화\n",
        "scaled_data = scaler1.transform(df2)\n",
        "\n",
        "# 결과를 예측한다.\n",
        "y_pred1 = best_model1.predict(scaled_data)\n",
        "y_pred2 = best_model2.predict(scaled_data)\n",
        "y_pred3 = best_model3.predict(scaled_data)\n",
        "y_pred4 = best_model4.predict(scaled_data)\n",
        "\n",
        "# 예측 확률을 시각화한다.\n",
        "proba_data = best_model1.predict_proba(scaled_data)\n",
        "\n",
        "# 0일확률과 1일 확률 값을 각각 가져온다.\n",
        "a10 = proba_data[:, 0]\n",
        "a11 = proba_data[:, 1]\n",
        "\n",
        "plt.scatter(list(range(len(a10))), a10, label='0일 확률')\n",
        "plt.scatter(list(range(len(a11))), a11, label='1일 확률')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 예측 확률을 시각화한다.\n",
        "proba_data = best_model2.predict_proba(scaled_data)\n",
        "\n",
        "# 0일확률과 1일 확률 값을 각각 가져온다.\n",
        "a10 = proba_data[:, 0]\n",
        "a11 = proba_data[:, 1]\n",
        "\n",
        "plt.scatter(list(range(len(a10))), a10, label='0일 확률')\n",
        "plt.scatter(list(range(len(a11))), a11, label='1일 확률')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 예측 확률을 시각화한다.\n",
        "proba_data = best_model3.predict_proba(scaled_data)\n",
        "\n",
        "# 0일확률과 1일 확률 값을 각각 가져온다.\n",
        "a10 = proba_data[:, 0]\n",
        "a11 = proba_data[:, 1]\n",
        "\n",
        "plt.scatter(list(range(len(a10))), a10, label='0일 확률')\n",
        "plt.scatter(list(range(len(a11))), a11, label='1일 확률')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 예측 확률을 시각화한다.\n",
        "proba_data = best_model4.predict_proba(scaled_data)\n",
        "\n",
        "# 0일확률과 1일 확률 값을 각각 가져온다.\n",
        "a10 = proba_data[:, 0]\n",
        "a11 = proba_data[:, 1]\n",
        "\n",
        "plt.scatter(list(range(len(a10))), a10, label='0일 확률')\n",
        "plt.scatter(list(range(len(a11))), a11, label='1일 확률')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 결과 데이터를 복원한다.\n",
        "result_data1 = encoder1.inverse_transform(y_pred1)\n",
        "result_data2 = encoder1.inverse_transform(y_pred2)\n",
        "result_data3 = encoder1.inverse_transform(y_pred3)\n",
        "result_data4 = encoder1.inverse_transform(y_pred4)\n",
        "\n",
        "\n",
        "\n",
        "# 결과를 저장한다.\n",
        "df2['target'] = result_data1\n",
        "df2.to_csv('data/breast_cancer_AdaBoost.csv')\n",
        "\n",
        "\n",
        "df2['target'] = result_data2\n",
        "df2.to_csv('data/breast_cancer_GradianBoost.csv')\n",
        "\n",
        "df2['target'] = result_data3\n",
        "df2.to_csv('data/breast_cancer_LightGBM.csv')\n",
        "\n",
        "df2['target'] = result_data4\n",
        "df2.to_csv('data/breast_cancer_XGBoost.csv')\n",
        "\n",
        "\n",
        "print('저장완료')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4DEqSxNGq42"
      },
      "source": [
        "# 부스팅 회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_RrUF8ZGq8k"
      },
      "source": [
        "model1 = AdaBoostRegressor()\n",
        "model1 = GradientBoostingRegressor()\n",
        "model1 = LGBMRegressor()\n",
        "model1 = XGBRegressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZtbs1DIHwuK"
      },
      "source": [
        " - 회귀는 scoring='r2'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEEgzYhrHtlh"
      },
      "source": [
        "# 교차 검증 수행\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "\n",
        "r1 = cross_val_score(model , X, y, scoring='r2', cv=kfold)\n",
        "\n",
        "print(f'평균 성능 수치 : {r1.mean()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aBHfBikHto0"
      },
      "source": [
        "- 나머지는 분류와 동일함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN4fHT-yl3Ak"
      },
      "source": [
        "# Voting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKjr57ueHttI"
      },
      "source": [
        "## 앙상블\n",
        "- 하나의 단일 모델로 성능이 높지 않을 경우 다수의 모델을 사용하는 기법\n",
        "- 앙상블은 voting과 bagging으로 나눠진다.\n",
        "\n",
        "## bagging\n",
        "- 같은 모델을 다수 두고 다른 형태의 데이터를 학습 시키는 방법\n",
        "- 우리가 지금까지 살펴본 앙상블, 부스팅 알고리즘은 모두 bagging이다.\n",
        "\n",
        "## voing\n",
        "- 다른 모델을 다수 두고 같은 형태의 데이터를 학습 시키는 방법\n",
        "- sklearn에서 voting 을 제공한다.\n",
        "\n",
        "## 선정방식\n",
        "- hard voting : 각 알고리즘이 던지는 결과를 취합하여 다수결로 결정한다.\n",
        "- soft voting : 각 알고리즘이 던지는 정답 확률을 취합하여 확률이 가장 높은 걸로 결정한다.\n",
        "- 지금까지 배운 앙상블, 부스팅 알고리즘들은 soft voting을 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMEUxFXunFW_"
      },
      "source": [
        "## 학습을 위한 사전 작업"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHzsyAXTlzHk"
      },
      "source": [
        "#### 데이터 준비>데이터 전처리(X,y-인코딩( LabelEncoder())-표준화(StandardScaler()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBoC3TzxnIqz"
      },
      "source": [
        "### 기존 모델 사용\n",
        "- 부스팅에서 best_estimator_를 가져와서 입력하고 사용.\n",
        "- 즉, 최적의 파라미터 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eST2Rz3-HtyY"
      },
      "source": [
        "model1 = KNeighborsClassifier(n_neighbors=9)\n",
        "model2 = LogisticRegression(penalty='l2', C=0.1)\n",
        "model3 = SVC(C=1, probability=True)\n",
        "model4 = DecisionTreeClassifier(max_depth=4)\n",
        "model5 = RandomForestClassifier(max_depth=10, n_estimators=150)\n",
        "model6 = AdaBoostClassifier(learning_rate=1, n_estimators=300)\n",
        "model7 = GradientBoostingClassifier(learning_rate=1, n_estimators=150)\n",
        "model8 = LGBMClassifier(learning_rate=0.1, n_estimators=100)\n",
        "model9 = XGBClassifier(silent=True, verbosity=0, booster='gblinear', learning_rate=0.01, n_estimators=250)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Du5Ko01nt4l"
      },
      "source": [
        "### 교차 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwA1-KMsHt0c"
      },
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "\n",
        "r1 = cross_val_score(model1, X, y, scoring='f1', cv=kfold)\n",
        "r2 = cross_val_score(model2, X, y, scoring='f1', cv=kfold)\n",
        "r3 = cross_val_score(model3, X, y, scoring='f1', cv=kfold)\n",
        "r4 = cross_val_score(model4, X, y, scoring='f1', cv=kfold)\n",
        "r5 = cross_val_score(model5, X, y, scoring='f1', cv=kfold)\n",
        "r6 = cross_val_score(model6, X, y, scoring='f1', cv=kfold)\n",
        "r7 = cross_val_score(model7, X, y, scoring='f1', cv=kfold)\n",
        "r8 = cross_val_score(model8, X, y, scoring='f1', cv=kfold)\n",
        "r9 = cross_val_score(model9, X, y, scoring='f1', cv=kfold)\n",
        "\n",
        "print(r1.mean())\n",
        "print(r2.mean())\n",
        "print(r3.mean())\n",
        "print(r4.mean())\n",
        "print(r5.mean())\n",
        "print(r6.mean())\n",
        "print(r7.mean())\n",
        "print(r8.mean())\n",
        "print(r9.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-LLHK_anyBk"
      },
      "source": [
        "### Voting 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5D3Ig2An0Mo"
      },
      "source": [
        "# 사용할 알고리즘들..\n",
        "model_list = [\n",
        "    ('model1', model1), ('model2', model2), ('model3', model3),\n",
        "    ('model4', model4), ('model5', model5), ('model6', model6),\n",
        "    ('model7', model7), ('model8', model8), ('model9', model9),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUO_SoDqn0IG"
      },
      "source": [
        "# 하드 보팅\n",
        "model10 = VotingClassifier(estimators=model_list, voting='hard')\n",
        "\n",
        "r10 = cross_val_score(model10, X, y, scoring='f1', cv=kfold)\n",
        "r10.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IozBb8t3n0FJ"
      },
      "source": [
        "# 소프트 보팅\n",
        "model11 = VotingClassifier(estimators=model_list, voting='soft')\n",
        "\n",
        "r11 = cross_val_score(model11, X, y, scoring='f1', cv=kfold)\n",
        "r11.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AItk3cLOn5h2"
      },
      "source": [
        "### 전체 데이터를 학습한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epGOtmonn0C-"
      },
      "source": [
        "model10.fit(X, y)\n",
        "model11.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oatnSv-0n8IG"
      },
      "source": [
        "### 학습 데이터를 넣어서 검증을 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuNPq4hhnz_v"
      },
      "source": [
        "# 예측결과를 시각화 해본다.\n",
        "y_pred10 = model10.predict(X)\n",
        "\n",
        "plt.scatter(list(range(len(y))), y, label='original')\n",
        "plt.scatter(list(range(len(y_pred10))), y_pred10, label='prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH7mHjyOnz89"
      },
      "source": [
        "# 예측결과를 시각화 해본다.\n",
        "y_pred11 = model11.predict(X)\n",
        "\n",
        "plt.scatter(list(range(len(y))), y, label='original')\n",
        "plt.scatter(list(range(len(y_pred11))), y_pred11, label='prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CcDHwvloI1N"
      },
      "source": [
        "- 하드 보팅은 확률로 표현되지 않는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9roKOsamnz6F"
      },
      "source": [
        "# 결과 확률\n",
        "proba_a1 = model11.predict_proba(X)\n",
        "\n",
        "# 0일 확률들\n",
        "a10 = proba_a1[:, 0]\n",
        "# 1일 확률들\n",
        "a11 = proba_a1[:, 1]\n",
        "\n",
        "plt.scatter(list(range(len(a10))), a10, label='0일 확률')\n",
        "plt.scatter(list(range(len(a11))), a11, label='1일 확률')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lofDH_1noyOj"
      },
      "source": [
        "# Voting 회귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93ErYAj4o3UJ"
      },
      "source": [
        "### 기존 모델 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3L0QOpenzUb"
      },
      "source": [
        "model1 = KNeighborsRegressor(n_neighbors=3)\n",
        "model2 = LinearRegression()\n",
        "model3 = Ridge(alpha=1)\n",
        "model4 = Lasso(alpha=0.0001)\n",
        "model5 = ElasticNet(alpha=0.01)\n",
        "model6 = SVR(C=100)\n",
        "model7 = DecisionTreeRegressor(max_depth=5)\n",
        "model8 = RandomForestRegressor(max_depth=10, n_estimators=250)\n",
        "model9 = AdaBoostRegressor(learning_rate=0.1, n_estimators=200)\n",
        "model10 = GradientBoostingRegressor(learning_rate=0.1, max_depth=3, n_estimators=150)\n",
        "model11 = LGBMRegressor(learning_rate=0.1, max_depth=2, n_estimators=300)\n",
        "model12 = XGBRegressor(booster='gbtree', learning_rate=0.1, max_depth=2, n_estimators=300)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}