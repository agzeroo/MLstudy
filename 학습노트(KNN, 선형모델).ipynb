{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "- 최근접 이웃 알고리즘\n",
    "- 가장 가까운 거리에 있는 K 개의 데이터의 값을 보고 결과를 예측\n",
    "- 학습 자체가 데이터를 저장하는 것만 하기 때문에 학습이라는 것이 존재하지 않는다.\n",
    "- 근처에 있는 값만 보고 예측하기 때문에 예측 속도도 빠르다.\n",
    "- 데이터따라 성능이 매우 좋지 않을 가능성이 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 경고 뜨지 않게 설정\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 그래프 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['figure.figsize'] = 20, 10\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 데이터 전처리 알고리즘\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 학습용과 검증용으로 나누는 함수\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 교차 검증\n",
    "# 지표를 하나만 설정할 경우\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 지표를 하나 이상 설정할 경우\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 모델의 최적의 하이퍼파라미터를 찾기 위한 도구\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 평가함수\n",
    "# 분류용\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 회귀용\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 머신러닝 알고리즘 - 분류\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 머신러닝 알고리즘 - 회귀\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 준비>데이터 전처리(X,y-인코딩( LabelEncoder())-표준화(StandardScaler()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 모델로 돌려본다\n",
    "- KNeighborsClassifier()\n",
    "- 기본으로 n_neighbors=5로 설정되어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이웃의 개수는 기본이 5로 설정되어 있다.\n",
    "model1=KNeighborsClassifier()\n",
    "\n",
    "#교차검증\n",
    "kfold=KFold(n_splits=10,shuffle=True,random_state=1)\n",
    "\n",
    "r1=cross_val_score(model1,X,y,scoring='f1',cv=kfold)\n",
    "\n",
    "print(f'평균정확도:{r1.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  GridSearchCV\n",
    "### 모델 하이퍼 파라미터 튜닝\n",
    "- 하이퍼 파라미터 : 모델의 학습 성능 향상을 위해 설정하는 값. \n",
    "- 잘못 설정되면 성능에 악영향을 미칠 수 있다.\n",
    "- n_neighbors : 이웃의 개수\n",
    "- 이웃의 개수가 많으면 편향될 확률이 높아진다.\n",
    "- X와y에 제일 적합한 파라미터를 알아 낼 수 있다.\n",
    "\n",
    "###### GridSearchCV 파라미터에 정해둔 params를 입력한다.( param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # 'n_neighbors' : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    'n_neighbors' : list(range(1, 11))\n",
    "}\n",
    "\n",
    "# 사용할 모델 객체를 생성한다.\n",
    "model2 = KNeighborsClassifier()\n",
    "\n",
    "# 최적의 하이퍼 파라미터를 찾는다\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "#최적 하이퍼 파라미터를 찾기위한 GridSearchCV 모델 생성\n",
    "grid_clf = GridSearchCV(model2, param_grid=params, scoring='f1', cv=kfold)\n",
    "\n",
    "#X와y에 대해 학습시킨다.\n",
    "grid_clf.fit(X, y)\n",
    "\n",
    "#X와y에 제일 적합한 파라미터를 알아 낼 수 있다.\n",
    "\n",
    "# 결과출력\n",
    "print(f'최적의 하이퍼 파라미터 : {grid_clf.best_params_}')\n",
    "print(f'최적의 모델 평균 성능 : {grid_clf.best_score_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### grid_clf.best_estimator_= 최적의 하이퍼파라미터가 셋팅된 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 하이퍼파라미터가 셋팅된 모델을 받아온다.\n",
    "best_model = grid_clf.best_estimator_\n",
    "# 학습\n",
    "best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델로 y를 예측한다.\n",
    "y_pred = best_model.predict(X)\n",
    "\n",
    "#얼마나 잘 학습되었는지 그래프로 표현\n",
    "\n",
    "#실제 y값 표현\n",
    "plt.scatter(list(range(len(y))), y, label='original')\n",
    "\n",
    "#예측 y값 표현\n",
    "plt.scatter(list(range(len(y_pred))), y_pred, label='prediction')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predict_proba= 확률로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확률\n",
    "proba_a1 = best_model.predict_proba(X)\n",
    "proba_a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그래프로 표현\n",
    "# 0일 확률들\n",
    "a10 = proba_a1[:, 0]\n",
    "# 1일 확률들\n",
    "a11 = proba_a1[:, 1]\n",
    "\n",
    "plt.scatter(list(range(len(a10))), a10, label='0일 확률')\n",
    "plt.scatter(list(range(len(a11))), a11, label='1일 확률')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새로운 데이터로 y값을예측해본다.\n",
    "- 데이터 준비(X값으로만 이루어진 데이터) >데이터 전처리(표준화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 예측한다.\n",
    "y_pred = best_model.predict(새로운 데이터 X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 확률을 시각화한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 결과 데이터 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 데이터를 복원한다.\n",
    "result_data = encoder1.inverse_transform(y_pred)\n",
    "result_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 저장한다.\n",
    "df2['target'] = result_data\n",
    "df2.to_csv('data/breast_cancer_KNN.csv')\n",
    "print('저장완료')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 준비>데이터 전처리(X,y-인코딩( LabelEncoder())-표준화(StandardScaler()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor() 기본 모델 사용하기 \n",
    "- n_neighbors : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 생성\n",
    "model1=KNeighborsRegressor()\n",
    "\n",
    "#교차검증 수행\n",
    "kfold= KFold(n_splits=10,shuffle=True, random_state=1)\n",
    "r1= cross_val_score(model1,X,y,scoring='r2',cv=kfold)\n",
    "print(f'평균 성능 수치 : {r1.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 하이퍼 파라미터 튜닝>학습>검증>새로운데이터로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # 이웃의 개수\n",
    "    'n_neighbors' : list(range(1, 11))\n",
    "}\n",
    "\n",
    "\n",
    "kfold=KFold(n_splits=10,shuffle=True, random_state=1)\n",
    "\n",
    "model2=KNeighborsRegressor()\n",
    "grid_clf=GridSearchCV(model2,param_grid=params, scoring='r2',cv=kfold)\n",
    "\n",
    "grid_clf.fit(X,y)\n",
    "print(f'최적의 하이퍼 파라미터 : {grid_clf.best_params_}')\n",
    "print(f'최적의 모델 평균성능 : {grid_clf.best_score_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#진짜 결과와 예측 결과를 시각화하여 패턴을 학인\n",
    "plt.plot(y,label='original')\n",
    "plt.plot(y_pred, label='prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['target'] = y_pred\n",
    "df2.to_csv('data/boston_KNN.csv')\n",
    "print('저장완료')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형모델\n",
    "- 데이터를 확인하고 그 와 관련된 선을 찾는 알고리즘\n",
    "- 분류 : 경계선을 찾는다.\n",
    "- 회귀 : 예측선을 찾는다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 준비>데이터 전처리(X,y-인코딩( LabelEncoder())-표준화(StandardScaler()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 모델 사용\n",
    "- LogisticRegression : 경계선과 가장 가까운 데이터와의 거리가 가장 가까울 수 있도록 경계선을 찾는다.\n",
    "- SVM(SVC) : 경계선과 가장 가까운 데이터와의 거리가 가장 멀 수 있도록 경계선을 찾는다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LogisticRegression()\n",
    "\n",
    "# 교차 검증\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "r1 = cross_val_score(model1, X, y, scoring='f1', cv=kfold)\n",
    "\n",
    "print(f'평균 정확도 : {r1.mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SVC()\n",
    "\n",
    "# 교차 검증\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "r1 = cross_val_score(model2, X, y, scoring='f1', cv=kfold)\n",
    "\n",
    "print(f'평균 정확도 : {r1.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 하이퍼 파라미터 튜닝\n",
    "- 규제 : 선형 모델은 직선을 찾으려고 한다. 따라서 규제를 통해 직선을 다른 형태로 변형할 수 있다.\n",
    "- l2 규제 : 각 가중치(학습을 통해 찾아내야 하는 상수들)의 제곱한 값의 합에 규제 강도를 곱한다. 규제 강도를 크게하면 가중치가 더 많이 감소되고 규제 강도를 작게하면 가중치가 증가한다.\n",
    "- l1 규제 : 각 가중치의 합에 규제 강도를 곱한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- penalty : 규제의 종류(l1, l2, elasticnet, none)\n",
    "- C : 규제의 강도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "}\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "grid_clf1 = GridSearchCV(model1, param_grid=params, scoring='f1', cv=kfold)\n",
    "grid_clf1.fit(X, y)\n",
    "print(f'최적의 하이퍼 파라미터 : {grid_clf1.best_params_}')\n",
    "print(f'최적의 모델 평균 성능 : {grid_clf1.best_score_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM(SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM은 penalty가 l2로 고정되어 있다####\n",
    "- C : 규제의 강도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'C' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "}\n",
    "\n",
    "model2 = SVC()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "grid_clf2 = GridSearchCV(model2, param_grid=params, scoring='f1', cv=kfold)\n",
    "grid_clf2.fit(X, y)\n",
    "print(f'최적의 하이퍼 파라미터 : {grid_clf2.best_params_}')\n",
    "print(f'최적의 모델 평균 성능 : {grid_clf2.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적의 모델에 전체 데이터를 학습 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 하이퍼파라미터가 셋팅된 모델을 받아온다.\n",
    "\n",
    "# LogisticRegression()\n",
    "best_model1 = grid_clf1.best_estimator_\n",
    "\n",
    "# SVC()\n",
    "best_model2 = grid_clf2.best_estimator_\n",
    "\n",
    "# SVM의 경우 확률을 찍어보기 위해서는 다음과 같은 값을 설정해야 한다.\n",
    "best_model2.probability = True\n",
    "\n",
    "# 학습\n",
    "best_model1.fit(X, y)\n",
    "best_model2.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습한 데이터를 통해 검증한다. \n",
    "- LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = best_model1.predict(X)\n",
    "\n",
    "plt.scatter(list(range(len(y))), y, label='original')\n",
    "plt.scatter(list(range(len(y_pred1))), y_pred1, label='prediction')\n",
    "plt.legend()\n",
    "plt.title('LogisticRegression')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확률\n",
    "proba_a1 = best_model1.predict_proba(X)\n",
    "\n",
    "# 0일 확률들\n",
    "a10 = proba_a1[:, 0]\n",
    "# 1일 확률들\n",
    "a11 = proba_a1[:, 1]\n",
    "\n",
    "plt.scatter(list(range(len(a10))), a10, label='0일 확률')\n",
    "plt.scatter(list(range(len(a11))), a11, label='1일 확률')\n",
    "plt.legend()\n",
    "plt.title('LogisticRegression')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = best_model2.predict(X)\n",
    "\n",
    "plt.scatter(list(range(len(y))), y, label='original')\n",
    "plt.scatter(list(range(len(y_pred2))), y_pred2, label='prediction')\n",
    "plt.legend()\n",
    "plt.title('SVM(SVC)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 확률\n",
    "proba_a1 = best_model2.predict_proba(X)\n",
    "\n",
    "# 0일 확률들\n",
    "a10 = proba_a1[:, 0]\n",
    "# 1일 확률들\n",
    "a11 = proba_a1[:, 1]\n",
    "\n",
    "plt.scatter(list(range(len(a10))), a10, label='0일 확률')\n",
    "plt.scatter(list(range(len(a11))), a11, label='1일 확률')\n",
    "plt.legend()\n",
    "plt.title('SVM(SVC)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새로운 데이터에 대한 예측을 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 준비>데이터 전처리(표준화(StandardScaler())>결과 예측>시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀\n",
    "- LinearRegression : 가장 기본적인 선형 회귀. 규제 함수가 없다.\n",
    "- Ridge:LinearRegression에 규제함수 l2를 추가한것\n",
    "- Lasso: LinearRegression에 규제함수 l1를 추가한것\n",
    "- ElasticNet:Ridge와Lasso 결합\n",
    "- SVM(SVR): 서브백터머신 방식으로 회귀를 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 준비>데이터 전처리(X,y-인코딩( LabelEncoder())-표준화(StandardScaler()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본모델 사용하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearRegression()\n",
    "model2 = Ridge()\n",
    "model3 = Lasso()\n",
    "model4 = ElasticNet()\n",
    "model5 = SVR()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증 수행\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "r1 = cross_val_score(model1, X, y, scoring='r2', cv=kfold)\n",
    "r2 = cross_val_score(model2, X, y, scoring='r2', cv=kfold)\n",
    "r3 = cross_val_score(model3, X, y, scoring='r2', cv=kfold)\n",
    "r4 = cross_val_score(model4, X, y, scoring='r2', cv=kfold)\n",
    "r5 = cross_val_score(model5, X, y, scoring='r2', cv=kfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'평균 성능 수치 : {r1.mean()}')\n",
    "print(f'평균 성능 수치 : {r2.mean()}')\n",
    "print(f'평균 성능 수치 : {r3.mean()}')\n",
    "print(f'평균 성능 수치 : {r4.mean()}')\n",
    "print(f'평균 성능 수치 : {r5.mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearRegressino 은 규제 함수가 존재하지 않기 때문에 설정할 하이퍼\n",
    "# 파라미터가 존재하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha : 값이 작을 수록 규제가 약해지고 값이 클수록 규제가 강해진다.\n",
    "params = {\n",
    "    'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "}\n",
    "\n",
    "model2 = Ridge()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "grid_clf2 = GridSearchCV(model2, param_grid=params, scoring='r2', cv=kfold)\n",
    "grid_clf2.fit(X, y)\n",
    "print(f'최적의 하이퍼 파라미터 : {grid_clf2.best_params_}')\n",
    "print(f'최적의 모델 평균성능 : {grid_clf2.best_score_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha : 값이 작을 수록 규제가 약해지고 값이 클수록 규제가 강해진다.\n",
    "params = {\n",
    "    'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "}\n",
    "\n",
    "model3 = Lasso()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "grid_clf3 = GridSearchCV(model3, param_grid=params, scoring='r2', cv=kfold)\n",
    "grid_clf3.fit(X, y)\n",
    "print(f'최적의 하이퍼 파라미터 : {grid_clf3.best_params_}')\n",
    "print(f'최적의 모델 평균성능 : {grid_clf3.best_score_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha : 값이 작을 수록 규제가 약해지고 값이 클수록 규제가 강해진다.\n",
    "params = {\n",
    "    'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "}\n",
    "\n",
    "model4 = ElasticNet()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "grid_clf4 = GridSearchCV(model4, param_grid=params, scoring='r2', cv=kfold)\n",
    "grid_clf4.fit(X, y)\n",
    "print(f'최적의 하이퍼 파라미터 : {grid_clf4.best_params_}')\n",
    "print(f'최적의 모델 평균성능 : {grid_clf4.best_score_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM(SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C : 규제의 강도 \n",
    "params = {\n",
    "    'C' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "}\n",
    "\n",
    "model5 = SVR()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "grid_clf5 = GridSearchCV(model5, param_grid=params, scoring='r2', cv=kfold)\n",
    "grid_clf5.fit(X, y)\n",
    "print(f'최적의 하이퍼 파라미터 : {grid_clf5.best_params_}')\n",
    "print(f'최적의 모델 평균성능 : {grid_clf5.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1 = LinearRegression()\n",
    "best_model2 = grid_clf2.best_estimator_\n",
    "best_model3 = grid_clf3.best_estimator_\n",
    "best_model4 = grid_clf4.best_estimator_\n",
    "best_model5 = grid_clf5.best_estimator_\n",
    "\n",
    "print(best_model1)\n",
    "print(best_model2)\n",
    "print(best_model3)\n",
    "print(best_model4)\n",
    "print(best_model5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1.fit(X, y)\n",
    "best_model2.fit(X, y)\n",
    "best_model3.fit(X, y)\n",
    "best_model4.fit(X, y)\n",
    "best_model5.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이터를 가지고 검증한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터를 통해 예측 결과를 가져온다\n",
    "y_pred1 = best_model1.predict(X)\n",
    "y_pred2 = best_model2.predict(X)\n",
    "y_pred3 = best_model3.predict(X)\n",
    "y_pred4 = best_model4.predict(X)\n",
    "y_pred5 = best_model5.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 진짜 결과와 예측 결과를 시각화하여 패턴을 확인한다.\n",
    "plt.plot(y, label='original')\n",
    "plt.plot(y_pred1(2,3,4,5), label='prediction')\n",
    "plt.legend()\n",
    "plt.title('LinearRegression')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새로운 데이터에 대한 예측을 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 준비>데이터 전처리(표준화(StandardScaler())>결과 예측>시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측결과 추출\n",
    "y_pred1 = best_model1.predict(scaled_data)\n",
    "y_pred2 = best_model2.predict(scaled_data)\n",
    "y_pred3 = best_model3.predict(scaled_data)\n",
    "y_pred4 = best_model4.predict(scaled_data)\n",
    "y_pred5 = best_model5.predict(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['target'] = y_pred1\n",
    "df2.to_csv('data/boston_LinearRegression.csv')\n",
    "\n",
    "df2['target'] = y_pred2\n",
    "df2.to_csv('data/boston_Ridge.csv')\n",
    "\n",
    "df2['target'] = y_pred3\n",
    "df2.to_csv('data/boston_Lasso.csv')\n",
    "\n",
    "df2['target'] = y_pred4\n",
    "df2.to_csv('data/boston_ElasticNet.csv')\n",
    "\n",
    "df2['target'] = y_pred5\n",
    "df2.to_csv('data/boston_SVR.csv')\n",
    "\n",
    "print('저장완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
